# 完整的增强剪枝策略配置示例
# 展示如何启用所有新功能：cosine + plateau 调度、HardConcrete 温度退火、学习率退火、SWA

### 基础训练配置
exp_dir: exp/enhanced_pruning_full_$(date +%Y%m%d_%H%M%S)
gpus: "[0,1,2,3,4,5,6,7]"
num_avg: 2
enable_amp: False
do_lm: False

seed: 42
num_epochs: 20
save_epoch_interval: 1
log_batch_interval: 100

dataloader_args:
  batch_size: 128 
  num_workers: 8
  pin_memory: False
  prefetch_factor: 6
  drop_last: True

dataset_args:
  sample_num_per_epoch: 0
  shuffle: True
  shuffle_args:
    shuffle_size: 2500
  filter: True
  filter_args:
    min_num_frames: 50
    max_num_frames: 400
  resample_rate: 16000
  speed_perturb: False
  num_frms: 150
  aug_prob: 0.6
  frontend: "huggingface"
  huggingface_args:
    upstream_args:
      name: "wavlm_base_plus"
      path_or_url: "/path/to/wavlm_base_plus.hf.pth"
      pruning_units: "conv,head,attlayer,interm,ffnlayer"
    frozen: False
    frame_shift: 20
    frame_length: 20
  cmvn: True
  cmvn_args:
    norm_mean: True
    norm_var: False
  spec_aug: False
  spec_aug_args:
    num_t_mask: 1
    num_f_mask: 1
    max_t: 10
    max_f: 8
    prob: 0.6

model: SSL_BACKEND_MHFA
model_init: null
model_args:
  feat_dim: -1
  head_nb: 32
  embed_dim: 256
  compression_dim: 128
  feature_grad_mult: 0.1
  nb_layer: 13

projection_args:
  project_type: "arc_margin_intertopk_subcenter"
  scale: 32.0
  easy_margin: False

margin_scheduler: MarginScheduler
margin_update:
  initial_margin: 0.2
  final_margin: 0.2
  increase_start_epoch: 1
  fix_start_epoch: 1
  update_margin: True
  increase_type: "exp"

loss: CrossEntropyLoss
loss_args: {}

optimizer: AdamW
optimizer_args:
  weight_decay: 1.0e-7

scheduler: ExponentialDecrease
scheduler_args:
  initial_lr: 1.0e-4
  final_lr: 1.0e-6
  warm_up_epoch: 2
  warm_from_zero: True

# ===== 增强剪枝配置 =====
use_pruning_loss: True
target_sparsity: 0.7
initial_reg_lr: 5.0e-2
sparsity_warmup_epochs: 8
sparsity_schedule: "cosine_plateau"  # 新增：cosine + plateau 调度
min_sparsity: 0.0
lambda_pair: [1.0, 5.0]

# Plateau 配置
plateau_start_ratio: 0.9  # 90% 训练步后开始 plateau 阶段

# 学习率退火配置
use_plateau_lr_decay: True  # 启用学习率 plateau 退火
lr_decay_factor: 0.1        # plateau 阶段学习率衰减到 10%
min_lr_ratio: 0.01          # 最小学习率为初始学习率的 1%

# HardConcrete 温度退火配置
min_temperature: 0.1           # 最小温度
temperature_decay: 0.95        # 温度衰减因子
temperature_decay_freq: 100    # 每100步衰减一次温度

# SWA 配置
use_swa: True              # 启用随机权重平均
swa_start_ratio: 0.9       # 90% 训练步后开始 SWA
swa_update_freq: 10        # 每10步更新一次 SWA

# ===== 量化配置（可选） =====
use_quantization: False    # 设置为 True 启用量化训练
quantization_config: '8bit_symmetric'
quantize_weights: True
quantize_activations: False
preserve_hp_gating: True
freeze_lsq_steps: 2000
lsq_step_lr: 1e-5
grad_clip_norm: 1.0
per_channel_weights: True
per_channel_activations: False
quantize_bias: False
